[llm]
model = "deepseek-chat"        # The LLM model to use
base_url = "https://api.deepseek.com/v1"  # API endpoint URL
api_key = "sk-82957ebf79174747b085ba495b78eeed"                    # Your API key
max_tokens = 8192                           # Maximum number of tokens in the response
temperature = 0.0                           # Controls randomness